{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/openai/shap-e.git"
      ],
      "metadata": {
        "id": "_lUBW1QRxScQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%cd shap-e"
      ],
      "metadata": {
        "id": "NPvBx4MvxY1P",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d3ac56dd-2801-4167-8766-c65ffec9fbbc"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/shap-e\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -e ."
      ],
      "metadata": {
        "id": "eSNibnY8xewk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install langchain langchain-community\n",
        "!pip install langchain-text-splitters\n",
        "!pip install langchain-classic\n",
        "!pip install -U langchain_ollama"
      ],
      "metadata": {
        "id": "IvzR7mcIxyqB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install chromadb trimesh unstructured"
      ],
      "metadata": {
        "id": "9Lpnc50aJkCI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# =========================\n",
        "# LangChain (API ACTUAL)\n",
        "# =========================\n",
        "from langchain_community.document_loaders import DirectoryLoader\n",
        "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
        "from langchain_community.embeddings import HuggingFaceEmbeddings\n",
        "from langchain_community.vectorstores import Chroma\n",
        "\n",
        "from langchain_classic.chains import create_retrieval_chain\n",
        "from langchain_ollama import OllamaEmbeddings, ChatOllama\n",
        "\n",
        "# =========================\n",
        "# Core libs\n",
        "# =========================\n",
        "import torch\n",
        "import trimesh\n",
        "\n",
        "# =========================\n",
        "# Shap-E\n",
        "# =========================\n",
        "from shap_e.diffusion.sample import sample_latents\n",
        "from shap_e.diffusion.gaussian_diffusion import diffusion_from_config\n",
        "from shap_e.models.download import load_model, load_config\n",
        "from shap_e.util.notebooks import (\n",
        "    decode_latent_mesh,\n",
        "    create_pan_cameras,\n",
        "    decode_latent_images,\n",
        "    gif_widget,\n",
        ")\n"
      ],
      "metadata": {
        "id": "-a11U5ij3XwF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.document_loaders import DirectoryLoader\n",
        "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
        "from langchain.embeddings import HuggingFaceEmbeddings\n",
        "from langchain_community.vectorstores import Chroma\n",
        "from langchain.chains import RetrievalQA\n",
        "from langchain_community.llms import Ollama\n",
        "import torch\n",
        "import trimesh\n",
        "\n",
        "\n",
        "\n",
        "from shap_e.diffusion.sample import sample_latents\n",
        "from shap_e.diffusion.gaussian_diffusion import diffusion_from_config\n",
        "from shap_e.models.download import load_model, load_config\n",
        "from shap_e.util.notebooks import create_pan_cameras, decode_latent_images, gif_widget, decode_latent_mesh"
      ],
      "metadata": {
        "id": "Fu8I1aK_x_Px"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ===========================================\n",
        "# cargar y dividir documentos 3D (texto)\n",
        "# ===========================================\n",
        "loader = DirectoryLoader(\"./3d_docs\", glob=\"**/*.txt\")\n",
        "docs = loader.load()\n",
        "\n",
        "splitter = RecursiveCharacterTextSplitter(\n",
        "    chunk_size=800,\n",
        "    chunk_overlap=200\n",
        ")\n",
        "\n",
        "chunks = splitter.split_documents(docs)\n",
        "\n",
        "embeddings = HuggingFaceEmbeddings(\n",
        "    model_name=\"sentence-transformers/all-MiniLM-L6-v2\"\n",
        ")\n"
      ],
      "metadata": {
        "id": "JuFZSIP4yFDB",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 356
        },
        "outputId": "a878d65a-79c0-4411-e233-7e9889e86ce4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "Directory not found: './3d_docs'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-3896938776.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;31m# ===========================================\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mloader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mDirectoryLoader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"./3d_docs\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mglob\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"**/*.txt\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mdocs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mloader\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m splitter = RecursiveCharacterTextSplitter(\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/langchain_community/document_loaders/directory.py\u001b[0m in \u001b[0;36mload\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    115\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mList\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mDocument\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    116\u001b[0m         \u001b[0;34m\"\"\"Load documents.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 117\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlazy_load\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    118\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    119\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mlazy_load\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mIterator\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mDocument\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/langchain_community/document_loaders/directory.py\u001b[0m in \u001b[0;36mlazy_load\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    121\u001b[0m         \u001b[0mp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mPath\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    122\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexists\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 123\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mFileNotFoundError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Directory not found: '{self.path}'\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    124\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_dir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    125\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Expected directory, got file: '{self.path}'\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: Directory not found: './3d_docs'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ===========================================\n",
        "# crear la base vectorial (ChromaDB)\n",
        "# ===========================================\n",
        "vectorstore = Chroma(\n",
        "    persist_directory=\"./chroma_db\",\n",
        "    embedding_function=embeddings\n",
        ")\n",
        "\n",
        "vectorstore.add_documents(chunks)\n",
        "\n",
        "retriever = vectorstore.as_retriever(search_kwargs={\"k\": 3})"
      ],
      "metadata": {
        "id": "HepXuP5GJCef"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# ===========================================\n",
        "# cadena RAG: recuperar + generar prompt 3D\n",
        "# ===========================================\n",
        "ollama_url= \"https://jonathan-enjoyed-rarely-bridges.trycloudflare.com\"\n",
        "\n",
        "llm = Ollama(\n",
        "    model=\"mistral\",\n",
        "    base_url=ollama_url,\n",
        "    )\n",
        "\n",
        "qa_chain = RetrievalQA.from_chain_type(\n",
        "    llm=llm,\n",
        "    retriever=retriever,\n",
        "    chain_type=\"stuff\",\n",
        ")\n",
        "\n",
        "query = \"a large meat knife\"\n",
        "prompt_3d = qa_chain.run(query)\n",
        "\n",
        "print(\"\\nüîç Prompt generado para Shap-E:\\n\", prompt_3d)\n"
      ],
      "metadata": {
        "id": "QHVv5-2bJG_2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ===========================================\n",
        "# generaci√≥n 3D con Shap-E\n",
        "# ===========================================\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "try:\n",
        "    x = torch.empty((1024, 1024, 256), device=device)\n",
        "    print(\"‚úÖ Tensor creado en GPU correctamente.\")\n",
        "except RuntimeError as e:\n",
        "    print(\"‚ùå Error al asignar tensor:\", e)\n",
        "\n",
        "decoder = load_model(\"decoder\", device=device)\n",
        "xm = load_model('transmitter', device=device)\n",
        "model = load_model('text300M', device=device)\n",
        "diffusion = diffusion_from_config(load_config('diffusion'))\n",
        "batch_size = 4\n",
        "guidance_scale = 15.0\n",
        "latents = sample_latents(\n",
        "    batch_size=batch_size,\n",
        "    model=model,\n",
        "    diffusion=diffusion,\n",
        "    guidance_scale=guidance_scale,\n",
        "    model_kwargs=dict(texts=[query] * batch_size),\n",
        "    progress=True,\n",
        "    clip_denoised=True,\n",
        "    use_fp16=False,\n",
        "    use_karras=True,\n",
        "    karras_steps=256,\n",
        "    sigma_min=1e-3,\n",
        "    sigma_max=160,\n",
        "    s_churn=0,\n",
        ")\n",
        "mesh = decode_latent_mesh(decoder, latents[0])\n",
        "# Convertir de shap-e mesh ‚Üí trimesh\n",
        "# tri = trimesh.Trimesh(\n",
        "#     vertices=mesh.verts.numpy(),\n",
        "#     faces=mesh.faces.numpy(),\n",
        "#     process=False\n",
        "# )\n",
        "# Convertir de shap-e mesh ‚Üí trimesh (pasar primero a CPU)\n",
        "tri = trimesh.Trimesh(\n",
        "    vertices=mesh.verts.cpu().numpy(),\n",
        "    faces=mesh.faces.cpu().numpy(),\n",
        "    process=False\n",
        ")\n",
        "\n",
        "tri.export(\"knife.obj\")\n",
        "\n",
        "print(\"\\n‚úÖ Modelo 3D generado: router_cisco_1941.obj\")"
      ],
      "metadata": {
        "id": "k3CuVspNJIhd"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}